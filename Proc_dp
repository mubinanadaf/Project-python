from datetime import datetime, timezone
import sys
from app.audits.audits import create_audits
from app.exceptions.exception_handler import (
    SQLConnectionError, QueryMissingOrEmptyError
)
from app.exceptions.exceptions import (
    log_and_publish_exception, exception_context
)

def process_data_pipeline(config, query_name):
    gcs_token = get_gcs_token()
    output_path = config["paths"]["output_path"]

    try:
        # 1️⃣ SQL Connection
        unix_start_time = int(datetime.now(timezone.utc).timestamp())
        conn = get_sql_connection(config)

        if not conn:
            raise SQLConnectionError("SQL connection failed")
        logger.info("SQL connection established successfully")

        unix_end_time = int(datetime.now(timezone.utc).timestamp())
        create_audits(output_path, gcs_token, ["SQL_CONNECTION"], unix_start_time, unix_end_time)
        logger.info("SQL connection audit logged.")

        # 2️⃣ Data Extraction
        unix_start_time = int(datetime.now(timezone.utc).timestamp())
        extracted_file, columns = fetch_large_data(conn, config, query_name)

        if extracted_file == "error" or not columns:
            raise QueryMissingOrEmptyError("Data extraction failed")
        logger.info("Data extraction completed successfully")

        unix_end_time = int(datetime.now(timezone.utc).timestamp())
        create_audits(output_path, gcs_token, ["DATA_EXTRACTION"], unix_start_time, unix_end_time)
        logger.info("Data extraction audit logged.")

        # 3️⃣ Generate AVRO schema
        unix_start_time = int(datetime.now(timezone.utc).timestamp())
        generate_avro_schema(config, query_name, columns)
        logger.info("AVRO schema creation successful")

        unix_end_time = int(datetime.now(timezone.utc).timestamp())
        create_audits(output_path, gcs_token, ["SCHEMA_GENERATION"], unix_start_time, unix_end_time)
        logger.info("Schema generation audit logged.")

        # 4️⃣ Convert to AVRO
        unix_start_time = int(datetime.now(timezone.utc).timestamp())
        generated_files, unix_end_time = convert_to_avro(config)
        logger.info("Data conversion to AVRO completed successfully")

        create_audits(output_path, gcs_token, ["AVRO_CONVERSION"], unix_start_time, unix_end_time)
        logger.info("Avro conversion audit logged.")

        # 5️⃣ Final Audit for generated files
        create_audits(output_path, gcs_token, generated_files, unix_start_time, unix_end_time)
        logger.info("Audit logs for files published successfully")

    except (SQLConnectionError, QueryMissingOrEmptyError) as e:
        logger.error(f"Pipeline failed at stage: {e}")
        with exception_context(object_name="Data Pipeline") as ctx:
            log_and_publish_exception(e, gcs_token, context=ctx)
        sys.exit(1)

    except Exception as e:
        logger.error(f"An unexpected error occurred in the data pipeline: {e}")
        with exception_context(object_name="Data Pipeline") as ctx:
            log_and_publish_exception(e, gcs_token, context=ctx)
        sys.exit(1)
