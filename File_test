# tests/test_odin_bq_bq_data_load_dag.py
import importlib
import types
from datetime import timedelta

import pytest
from airflow.models import DAG
from airflow.operators.python import PythonOperator


def load_module():
    """
    Import the DAG module.
    Change the dotted path if your file is not top-level.
    Example: importlib.import_module("dags.odin_bq_bq_data_load")
    """
    mod = importlib.import_module("odin_bq_bq_data_load")
    assert isinstance(mod, types.ModuleType)
    return mod


def get_task(dag: DAG, task_id: str) -> PythonOperator:
    assert task_id in dag.task_ids, f"Missing task_id={task_id}"
    task = dag.get_task(task_id)
    assert isinstance(task, PythonOperator), f"{task_id} is not a PythonOperator"
    return task


def test_dag_metadata_and_defaults():
    mod = load_module()
    dag: DAG = getattr(mod, "dag")
    assert isinstance(dag, DAG)

    # DAG settings from your screenshots
    assert dag.dag_id == "odin_bq_bq_data_load"
    assert dag.catchup is False
    assert dag.schedule_interval is None
    assert getattr(dag, "max_active_runs", 25) == 25

    defaults = dag.default_args or {}
    assert defaults.get("depends_on_past") is False
    assert "start_date" in defaults
    assert defaults.get("retries") == 3
    assert defaults.get("retry_delay") == timedelta(minutes=1)


@pytest.mark.parametrize(
    "task_id, callable_name",
    [
        ("run_time_variables", "run_time_variables"),
        ("dimc_pre_check", "dimc_pre_check"),
        ("data_load_write_disposition", "data_load_write_disposition"),
        ("data_load_task", "data_load_task"),
        ("dimc_post_check", "dimc_post_check"),
    ],
)
def test_tasks_exist_and_have_callable(task_id, callable_name):
    mod = load_module()
    dag: DAG = getattr(mod, "dag")

    task = get_task(dag, task_id)

    # callable may be imported into the DAG module or referenced from utils
    fn = getattr(mod, callable_name, None)
    if fn is None:
        utils_mod = importlib.import_module("utils.cdp_common_functions")
        fn = getattr(utils_mod, callable_name)

    assert task.python_callable is fn
    # You set provide_context=True in your DAG
    assert getattr(task, "provide_context", True) is True
    # Both callbacks should be set
    assert callable(getattr(task, "on_success_callback"))
    assert callable(getattr(task, "on_failure_callback"))


def test_dependency_chain():
    mod = load_module()
    dag: DAG = getattr(mod, "dag")

    chain = [
        "run_time_variables",
        "dimc_pre_check",
        "data_load_write_disposition",
        "data_load_task",
        "dimc_post_check",
    ]

    for upstream, downstream in zip(chain, chain[1:]):
        u = get_task(dag, upstream)
        assert (
            downstream in u.downstream_task_ids
        ), f"{upstream} should flow to {downstream}"
,.........


# tests/test_odin_bq_bq_data_load_dag.py
import unittest
from unittest import mock
import importlib
from airflow.models import DAG
from airflow.operators.python import PythonOperator


class TestOdinBqBqDataLoadDag(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        # Import the DAG module
        cls.mod = importlib.import_module("odin.dag.odin_bq_bq_data_load")
        cls.dag: DAG = getattr(cls.mod, "dag")

    def test_dag_metadata(self):
        dag = self.dag
        self.assertEqual(dag.dag_id, "odin_bq_bq_data_load")
        self.assertFalse(dag.catchup)
        self.assertIsNone(dag.schedule_interval)
        self.assertEqual(getattr(dag, "max_active_runs", 25), 25)

        defaults = dag.default_args or {}
        self.assertIn("start_date", defaults)
        self.assertEqual(defaults.get("retries"), 3)
        self.assertEqual(defaults.get("depends_on_past"), False)

    def test_all_tasks_present(self):
        expected_tasks = [
            "run_time_variables",
            "dimc_pre_check",
            "data_load_write_disposition",
            "data_load_task",
            "dimc_post_check",
        ]
        for task_id in expected_tasks:
            self.assertIn(task_id, self.dag.task_ids)

            task = self.dag.get_task(task_id)
            self.assertIsInstance(task, PythonOperator)
            self.assertTrue(callable(task.on_success_callback))
            self.assertTrue(callable(task.on_failure_callback))

    def test_dependencies(self):
        chain = [
            "run_time_variables",
            "dimc_pre_check",
            "data_load_write_disposition",
            "data_load_task",
            "dimc_post_check",
        ]
        for upstream, downstream in zip(chain, chain[1:]):
            u = self.dag.get_task(upstream)
            self.assertIn(downstream, u.downstream_task_ids)

    @mock.patch("odin.dag.odin_bq_bq_data_load.run_time_variables")
    @mock.patch("odin.dag.odin_bq_bq_data_load.dimc_pre_check")
    @mock.patch("odin.dag.odin_bq_bq_data_load.data_load_write_disposition")
    @mock.patch("odin.dag.odin_bq_bq_data_load.data_load_task")
    @mock.patch("odin.dag.odin_bq_bq_data_load.dimc_post_check")
    def test_operator_callables_are_patched(
        self,
        mock_post,
        mock_load_task,
        mock_write_disp,
        mock_pre,
        mock_run_time,
    ):
        """
        This test ensures each PythonOperator is wired to the correct callable.
        By patching them, we can assert that the DAG references the patched objects.
        """
        task_ids = [
            ("run_time_variables", mock_run_time),
            ("dimc_pre_check", mock_pre),
            ("data_load_write_disposition", mock_write_disp),
            ("data_load_task", mock_load_task),
            ("dimc_post_check", mock_post),
        ]
        for task_id, mock_fn in task_ids:
            task = self.dag.get_task(task_id)
            self.assertIs(task.python_callable, mock_fn)


if __name__ == "__main__":
    unittest.main()
