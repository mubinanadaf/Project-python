def run_dq_scan(**context):
    """
    Trigger a DataScan run and return the long-running operation name.
    This name will be used by check_dq_scan_status to wait until completion.
    """
    headers = get_auth_headers()
    url = (
        f"https://dataplex.googleapis.com/v1/projects/{PROJECT_ID}"
        f"/locations/{REGION}/dataScans/{SCAN_ID}:run"
    )

    response = requests.post(url, headers=headers)
    print(f"Run DataScan response: {response.status_code} {response.text}")

    if response.status_code not in (200, 201):
        raise Exception(f"Failed to trigger DQ scan: {response.status_code} {response.text}")

    resp_json = response.json()
    op_name = resp_json.get("name")
    if not op_name:
        raise Exception(f"Run DQ scan did not return operation name: {resp_json}")

    print(f"Run operation name: {op_name}")
    # PythonOperator will push this return value to XCom
    return op_name

def check_dq_scan_status(**context):
    """
    Polls the long-running operation returned by run_dq_scan
    until it is done. If operation has 'error', task fails.
    """
    headers = get_auth_headers()

    ti = context["ti"]
    op_name = ti.xcom_pull(task_ids="run_dq_scan")
    if not op_name:
        raise Exception("No operation name found in XCom from run_dq_scan")

    op_url = f"https://dataplex.googleapis.com/v1/{op_name}"

    timeout_minutes = 15
    poll_interval_seconds = 30
    deadline = time.time() + timeout_minutes * 60

    last_resp = None

    while True:
        if time.time() > deadline:
            raise TimeoutError(
                f"Timed out waiting for DQ operation to finish; last_resp={last_resp}"
            )

        resp = requests.get(op_url, headers=headers)
        last_resp = resp.text
        print(f"Operation GET response: {resp.status_code} {resp.text}")

        if resp.status_code != 200:
            raise Exception(f"Failed to get operation: {resp.status_code} {resp.text}")

        op_json = resp.json()
        done = op_json.get("done", False)

        if done:
            # If there's an error, surface it
            if "error" in op_json:
                raise Exception(f"DQ operation finished with error: {op_json['error']}")
            print("DQ operation completed successfully (SUCCEEDED).")
            return

        print("DQ operation still running... waiting...")
        time.sleep(poll_interval_seconds

..............


def wait_for_dq_completion(**kwargs):
    ti = kwargs["ti"]

    # Get the return value of run_dq_scan
    job_name = ti.xcom_pull(task_ids="run_dq_scan")  # or key="return_value"
    if not job_name:
        raise AirflowException("No job_name returned from run_dq_scan")

    headers = get_auth_headers()
    job_url = f"{DATAPLEX_BASE_URL}/{job_name}"

    print(f"Polling DataScanJob at: {job_url}")

    terminal_states = ["SUCCEEDED", "FAILED", "CANCELLED", "ABORTED"]
    poll_interval_sec = 30
    max_wait_sec = 1800
    waited = 0
    last_state = None

    while waited < max_wait_sec:
        resp = requests.get(job_url, headers=headers)
        print(f"Job GET response: {resp.status_code} {resp.text}")
        resp.raise_for_status()

        job = resp.json()
        state = job.get("state")
        last_state = state
        print(f"Current DataScanJob state = {state}")

        if state in terminal_states:
            if state == "SUCCEEDED":
                print("DQ scan SUCCEEDED.")
                ti.xcom_push(key="dq_job_result", value=job)
                return
            else:
                raise AirflowException(
                    f"DQ scan finished in state {state}. Job: {job}"
                )

        print(f"Still running… waiting {poll_interval_sec} sec…")
        time.sleep(poll_interval_sec)
        waited += poll_interval_sec

    raise AirflowException(
        f"Timed out after {max_wait_sec} sec waiting for job. Last state={last_state}"
    )
