# bq_to_bq_spark.py
from pyspark.sql import SparkSession

def main():
    spark = (
        SparkSession.builder
        .appName("bq-to-bq-serverless")
        .getOrCreate()
    )

    # ---- Read from BigQuery ----
    # These will be passed as args from Dataproc batch
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_table", required=True)
    parser.add_argument("--output_table", required=True)
    args, _ = parser.parse_known_args()

    # Example: args.input_table = "project.dataset.source_table"
    #          args.output_table = "project.dataset.target_table"

    df = (
        spark.read.format("bigquery")
        .option("table", args.input_table)
        .load()
    )

    # Do any transformations here
    # For now, simple passthrough
    transformed = df  # .select(...), .withColumn(...), etc.

    # ---- Write to BigQuery ----
    (
        transformed.write
        .format("bigquery")
        .option("table", args.output_table)
        .mode("append")      # or "overwrite" for full load
        .save()
    )

    spark.stop()

if __name__ == "__main__":
    main()
