# tests/test_odin_bq_bq_data_load_dag.py
import os
import sys
import types
import importlib
import unittest
from unittest.mock import MagicMock


class TestBqToBqDataLoadDag(unittest.TestCase):
    def setUp(self):
        # ---------------- Mock airflow like in your samples ----------------
        self.mock_dag_instance = MagicMock(name="mock_dag")

        # Minimal DAG class that stores tasks; airflow.DAG() returns mock instance
        class FakeDAG:
            def __init__(self, **kwargs):
                # We still return your mock_dag_instance (sample style)
                pass

        fake_airflow = types.ModuleType("airflow")
        fake_airflow_models = types.ModuleType("airflow.models")
        fake_airflow_utils_dates = types.ModuleType("airflow.utils.dates")
        fake_airflow_operators = types.ModuleType("airflow.operators")
        fake_airflow_operators_python = types.ModuleType("airflow.operators.python")

        # DAG constructor → returns the same mocked DAG instance
        fake_airflow.DAG = MagicMock(return_value=self.mock_dag_instance)
        # days_ago helper (if used in default_args)
        fake_airflow_utils_dates.days_ago = MagicMock(return_value=0)

        # --------- Fake PythonOperator that captures task wiring ----------
        created = {}  # task_id -> fake operator

        class FakePythonOperator:
            def __init__(self, *, task_id, python_callable=None,
                         on_success_callback=None, on_failure_callback=None, dag=None, **_):
                self.task_id = task_id
                self.python_callable = python_callable
                self.on_success_callback = on_success_callback
                self.on_failure_callback = on_failure_callback
                self.upstream_task_ids = set()
                self.downstream_task_ids = set()
                # record; your module can retrieve tasks later via dag.get_task if you expose it,
                # but we verify from our registry
                created[task_id] = self
                # attach onto mock dag so we can access list of tasks if needed
                if not hasattr(self.mock_dag_instance, "tasks"):
                    self.mock_dag_instance.tasks = []
                self.mock_dag_instance.tasks.append(self)

            # support a >> b chaining
            def __rshift__(self, other):
                targets = other if isinstance(other, (list, tuple)) else [other]
                for t in targets:
                    self.downstream_task_ids.add(t.task_id)
                    t.upstream_task_ids.add(self.task_id)
                return other

        # install fakes into sys.modules (sample style)
        fake_airflow_operators_python.PythonOperator = FakePythonOperator
        sys.modules["airflow"] = fake_airflow
        sys.modules["airflow.models"] = fake_airflow_models
        sys.modules["airflow.utils"] = types.ModuleType("airflow.utils")
        sys.modules["airflow.utils.dates"] = fake_airflow_utils_dates
        sys.modules["airflow.operators"] = fake_airflow_operators
        sys.modules["airflow.operators.python"] = fake_airflow_operators_python

        # Store registries for assertions
        self._created_ops = created
        self._fake_airflow = fake_airflow

        # -------------- Mock your utils modules (sample style) -------------
        self.mock_log_audit = MagicMock(name="log_task_level_audit")
        sys.modules["utils.cdp_audit_logs"] = types.SimpleNamespace(
            log_task_level_audit=self.mock_log_audit
        )

        self.mock_run_time = MagicMock(name="run_time_variables")
        self.mock_pre = MagicMock(name="dimc_pre_check")
        self.mock_write_disp = MagicMock(name="data_load_write_disposition")
        self.mock_load = MagicMock(name="data_load_task")
        self.mock_post = MagicMock(name="dimc_post_check")

        sys.modules["utils.cdp_common_functions"] = types.SimpleNamespace(
            run_time_variables=self.mock_run_time,
            dimc_pre_check=self.mock_pre,
            data_load_write_disposition=self.mock_write_disp,
            data_load_task=self.mock_load,
            dimc_post_check=self.mock_post,
        )

        # Ensure src is on path (so import odin.dag.* resolves)
        if "PYTHONPATH" not in os.environ:
            sys.path.insert(0, os.path.abspath("src"))

        # -------------- Import module under test (after mocks installed) ---
        # Adjust path if your file name differs
        self.mod_path = "odin.dag.odin_bq_bq_data_load"
        self.mod = importlib.import_module(self.mod_path)

    def tearDown(self):
        for k in [
            "airflow",
            "airflow.models",
            "airflow.utils",
            "airflow.utils.dates",
            "airflow.operators",
            "airflow.operators.python",
            "utils.cdp_audit_logs",
            "utils.cdp_common_functions",
            self.mod_path,
        ]:
            sys.modules.pop(k, None)

    # ------------------------------ Tests ---------------------------------

    def test_dag_import_ok(self):
        # Matches your sample: import should not raise
        try:
            importlib.reload(self.mod)
        except Exception as e:
            self.fail(f"DAG import raised exception! {e!r}")

    def test_dag_constructor_args(self):
        # Validate DAG constructor was called with expected kwargs
        called_kwargs = self._fake_airflow.DAG.call_args.kwargs
        self.assertEqual(called_kwargs.get("dag_id"), "odin_bq_bq_data_load")
        self.assertIsNone(called_kwargs.get("schedule_interval"))
        self.assertFalse(called_kwargs.get("catchup", True))
        self.assertEqual(called_kwargs.get("max_active_runs"), 25)
        defaults = called_kwargs.get("default_args", {})
        self.assertIn("start_date", defaults)
        self.assertEqual(defaults.get("retries"), 3)

    def test_tasks_created_and_callables(self):
        expected_ids = [
            "run_time_variables",
            "dimc_pre_check",
            "data_load_write_disposition",
            "data_load_task",
            "dimc_post_check",
        ]
        for tid in expected_ids:
            self.assertIn(tid, self._created_ops, f"Missing operator for {tid}")

        # Ensure each operator wired to the expected callable
        self.assertIs(self._created_ops["run_time_variables"].python_callable, self.mock_run_time)
        self.assertIs(self._created_ops["dimc_pre_check"].python_callable, self.mock_pre)
        self.assertIs(self._created_ops["data_load_write_disposition"].python_callable, self.mock_write_disp)
        self.assertIs(self._created_ops["data_load_task"].python_callable, self.mock_load)
        self.assertIs(self._created_ops["dimc_post_check"].python_callable, self.mock_post)

    def test_dependency_chain(self):
        # Validate run_time_variables → dimc_pre_check → data_load_write_disposition → data_load_task → dimc_post_check
        rt = self._created_ops["run_time_variables"]
        pre = self._created_ops["dimc_pre_check"]
        wd = self._created_ops["data_load_write_disposition"]
        dl = self._created_ops["data_load_task"]
        post = self._created_ops["dimc_post_check"]

        self.assertEqual(rt.downstream_task_ids, {"dimc_pre_check"})
        self.assertEqual(pre.upstream_task_ids, {"run_time_variables"})
        self.assertEqual(pre.downstream_task_ids, {"data_load_write_disposition"})
        self.assertEqual(wd.upstream_task_ids, {"dimc_pre_check"})
        self.assertEqual(wd.downstream_task_ids, {"data_load_task"})
        self.assertEqual(dl.upstream_task_ids, {"data_load_write_disposition"})
        self.assertEqual(dl.downstream_task_ids, {"dimc_post_check"})
        self.assertEqual(post.upstream_task_ids, {"data_load_task"})
        self.assertEqual(post.downstream_task_ids, set())

    def test_callbacks(self):
        # run_time_variables has no callbacks; others have audit callbacks
        self.assertIsNone(self._created_ops["run_time_variables"].on_success_callback)
        self.assertIsNone(self._created_ops["run_time_variables"].on_failure_callback)

        for tid in [
            "dimc_pre_check",
            "data_load_write_disposition",
            "data_load_task",
            "dimc_post_check",
        ]:
            op = self._created_ops[tid]
            self.assertIs(op.on_success_callback, self.mock_log_audit)
            self.assertIs(op.on_failure_callback, self.mock_log_audit)


if __name__ == "__main__":
    unittest.main()
