üî∑ Execution Steps

This section describes the step-by-step execution of the Synthetic Data Generator to generate, convert, and deliver synthetic test data.


---

üìÑ 1Ô∏è‚É£ Synthetic Data Generation (Launchpad Server)

Synthetic customer and order data are generated on the launchpad server.
The data is generated in CSV format, saved to the specified path.

Supports configurable number of records (tested up to 100 million records).

customers and orders datasets are generated with realistic data using faker.

If generating orders, ensure a customer_ids.csv file exists and is used as input for customer_id assignment.


Command to execute:

python main.py

Output:

Customer CSV file: files_test/customers/customers_<timestamp>.csv

Orders CSV file: files_test/orders/orders_<timestamp>.csv



---

üìÑ 2Ô∏è‚É£ CSV ‚Üí Avro & Metadata (.ctl and .toc) Conversion (Launchpad Server)

Once the CSV files are created, they are converted into Avro format along with corresponding metadata files (.ctl and .toc).
This is done using a PySpark-based job that:

Reads the generated CSV.

Applies a predefined custom schema.

Produces .avro, .ctl, and .toc files into the configured output directory.


Command to execute:

python dataset_conversion_csv_to_avro_pass.py \
  -s <path_to_csv_file> \
  -d <output_directory> \
  -n <table_name> \
  -f <project_name>

Example:

python dataset_conversion_csv_to_avro_pass.py \
  -s ./files_test/orders/orders_100_rto.csv \
  -d ./avro_files/ \
  -n lfcr_demo \
  -f odin

Output:

Avro file: avro_files/<table_name>.avro

Metadata files: avro_files/<table_name>.ctl, avro_files/<table_name>.toc



---

üìÑ 3Ô∏è‚É£ Delivery & Downstream Processing

The .avro, .ctl, and .toc files can be uploaded to the CDMP platform or directly into GCS.

BigQuery ingestion and table partitioning can be triggered via Cloud Composer DAG (outside the scope of this document).


...........

Overview

This document describes the technical steps to generate synthetic test data for customers or orders, convert it to Avro + metadata files, and load it into BigQuery. It also explains how to customize schemas or parameters for future use.


---

üñ•Ô∏è Components

Component	Location	Purpose

main.py	csv_generator_bq_load/	Generates CSV data for specified schema
dataset_conversion_csv_to_avro_pass.py	project root	Converts CSV ‚Üí Avro + CTL/TOC
schemas/	csv_generator_bq_load/schemas/	Defines the columns and types for each dataset
generators.py	csv_generator_bq_load/	Defines data generation logic
files_test/	project root	Directory where generated CSV files are stored
avro_files/	project root	Directory where Avro & metadata files are stored



---

üöÄ Execution Steps

‚úÖ Prerequisites

Python ‚â• 3.7 installed.

Virtual environment activated.

Required Python packages installed:


pip install -r requirements.txt

Google Cloud credentials (if uploading to GCS/BigQuery).



---

1Ô∏è‚É£ Generate Synthetic CSV

Run the main.py script to generate CSV files for customers or orders.

cd csv_generator_bq_load
python main.py

By default:

customers_100.csv with 100 records ‚Üí saved in ../files_test/customers/

orders_100.csv with 100 records ‚Üí saved in ../files_test/orders/


You can adjust the record count and output name in main.py:

generate_file('customers', 'customers_1000', 1000)
generate_file('orders', 'orders_1000', 1000)


---

2Ô∏è‚É£ Convert CSV to Avro + Metadata

Run dataset_conversion_csv_to_avro_pass.py:

python dataset_conversion_csv_to_avro_pass.py \
    -s ../files_test/customers/customers_100.csv \
    -d avro_files/ \
    -n lfcr_demo \
    -f odin

This generates:

Avro file

.ctl and .toc metadata files

Output stored in avro_files/


Replace -s with the path to your CSV file.


---

3Ô∏è‚É£ Load into BigQuery

You can use the provided Airflow DAG (load_to_bq_dag.py) to load the Avro file into BigQuery, or run a manual bq command.

‚úÖ BigQuery table uses ingestion-time partitioning ‚Äî no snapshot date is required in the data.

Sample query to check data:

SELECT * FROM `project.dataset.orders`
WHERE _PARTITIONTIME = CURRENT_DATE()


---

üß© Customization

What to Change	How

Record count	Edit count parameter in main.py
Schema columns	Edit CUSTOMERS_SCHEMA or ORDERS_SCHEMA in schemas/
Add generator	Add function & mapping in generators.py
Output folder	Change path in generate_file() call


